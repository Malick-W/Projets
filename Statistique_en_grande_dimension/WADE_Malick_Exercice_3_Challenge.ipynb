{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communities and Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WADE El Hadji Malick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt    \n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pour les scores\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "#ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib # save and load models\n",
    "\n",
    "# # save the model to disk\n",
    "# filename = 'modeles/SVM'\n",
    "# joblib.dump(SVM, filename)\n",
    "\n",
    "# # load the model from disk\n",
    "# loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "path_Home = \"/home/jovyan/work/Projets/Projets/Statistique_en_grande_dimension/donnees_challenge\"\n",
    "#path = \"/users/mmath/wade/Bureau/Data/Statistique_en_grande_dimension\"\n",
    "\n",
    "Xtrainchallenge = pd.read_csv(path_Home + \"/Xtrainchallenge.txt\",  sep=' ')\n",
    "Ytrainchallenge = pd.read_csv(path_Home + \"/Ytrainchallenge.txt\",  sep=' ')\n",
    "\n",
    "Xtestchallenge = pd.read_csv(path_Home + \"/Xtestchallenge.txt\",  sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes:  1000\n",
      "Colonnes:  500\n",
      "---------------\n",
      "\n",
      "Variables:\n"
     ]
    }
   ],
   "source": [
    "print (\"Lignes: \" ,Xtrainchallenge.shape[0])\n",
    "print (\"Colonnes: \" ,Xtrainchallenge.shape[1])\n",
    "\n",
    "print(\"---------------\")\n",
    "print (\"\\nVariables:\")\n",
    "# print(Xtrainchallenge.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Col_train = Xtrainchallenge.std() > 1.5\n",
    "# Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "# Xtrainchallenge = Xtrainchallenge[Col_train]\n",
    "# Xtestchallenge = Xtestchallenge[Col_train]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xtrainchallenge,Ytrainchallenge,test_size = 0.3)\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.001, 0.005],\n",
    "#     \"min_samples_leaf\": [0.001, 0.005, 0.01, 0.01, 0.05],\n",
    "#     \"max_features\": [1., \"sqrt\"]\n",
    "#     }\n",
    "\n",
    "# clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "# clf_DT.fit(X_train, y_train)\n",
    "\n",
    "# end=time.time()\n",
    "# train_time_dec=end-start\n",
    "\n",
    "# print(\"Train: \",clf_DT.score(X_train, y_train))\n",
    "# print(\"Test: \",clf_DT.score(X_test, y_test))\n",
    "# print(\"\\n\")\n",
    "# print(clf_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrainchallenge = Xtrainchallenge[Col_train]\n",
    "# Xtestchallenge = Xtestchallenge[Col_train]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xtrainchallenge,Ytrainchallenge,test_size = 0.3)\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.001, 0.005],\n",
    "#     \"min_samples_leaf\": [0.001, 0.005, 0.01, 0.01, 0.05],\n",
    "#     \"max_features\": [1., \"sqrt\"]\n",
    "#     }\n",
    "\n",
    "# clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "# clf_DT.fit(X_train, y_train)\n",
    "\n",
    "# end=time.time()\n",
    "# train_time_dec=end-start\n",
    "\n",
    "# print(\"Train: \",clf_DT.score(X_train, y_train))\n",
    "# print(\"Test: \",clf_DT.score(X_test, y_test))\n",
    "# print(\"\\n\")\n",
    "# print(clf_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # On regarde la matrice de corrélation\n",
    "# fig = plt.figure(1, figsize=(50, 50))\n",
    "\n",
    "# # sns.heatmap(round(Xtrainchallenge.corr(),2), cmap=sns.diverging_palette(20, 220, n=200), fmt=\".2f\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (\"Lignes: \" ,Xtrainchallenge.shape[0])\n",
    "# print (\"Colonnes: \" ,Xtrainchallenge.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modèles de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.001, 0.005],\n",
    "#     \"min_samples_leaf\": [0.001, 0.005, 0.01, 0.01, 0.05],\n",
    "#     \"max_features\": [1., \"sqrt\"]\n",
    "#     }\n",
    "\n",
    "# clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "# clf_DT.fit(X_train, y_train)\n",
    "\n",
    "# end=time.time()\n",
    "# train_time_dec=end-start\n",
    "\n",
    "# print(\"Train: \",clf_DT.score(X_train, y_train))\n",
    "# print(\"Test: \",clf_DT.score(X_test, y_test))\n",
    "# print(\"\\n\")\n",
    "# print(clf_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = Xtrainchallenge\n",
    "# X_test = Xtestchallenge\n",
    "# y_train = Ytrainchallenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_components = 150\n",
    "\n",
    "# # TODO: Create an instance of PCA, initializing with n_components=n_components and whiten=True\n",
    "# pca = PCA(n_components=n_components, whiten=True, svd_solver='randomized')\n",
    "\n",
    "# #TODO: pass the training dataset (X_train) to pca's 'fit()' method\n",
    "# pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"proportion de variance associée aux 10 premiéres axes:\\n\",pca.explained_variance_ratio_[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"proportion total de variance associées aux axes: \",round(sum(pca.explained_variance_ratio_),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply dimensionality reduction to X.\n",
    "# X_train_pca = pca.transform(X_train)\n",
    "# X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_Logit = Logit_gscv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('WADE_premier_test.txt', np.transpose(y_pred_Logit))\n",
    "# y_pred_Logit = Logit_gscv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations sur les données de Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance = 10\n",
    "\n",
    "# Col_train = Xtrainchallenge.std() > variance\n",
    "# Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "# Col_test = Xtestchallenge.std() > variance\n",
    "# Col_test = [i for i in Col_test.index if Col_test[i]==True]\n",
    "\n",
    "# Col = list(set(Col_train) & set(Col_test))\n",
    "    \n",
    "# Xtrainchallenge = Xtrainchallenge[Col]\n",
    "# Xtestchallenge = Xtestchallenge[Col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# variance = 10\n",
    "\n",
    "# Col_train = Xtrainchallenge.std() > variance\n",
    "# Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "# Col_test = Xtestchallenge.std() > variance\n",
    "# Col_test = [i for i in Col_test.index if Col_test[i]==True]\n",
    "\n",
    "# Col = list(set(Col_train) & set(Col_test))\n",
    "    \n",
    "# Xtrainchallenge = Xtrainchallenge[Col]\n",
    "# Xtestchallenge = Xtestchallenge[Col]\n",
    "    \n",
    "    \n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.005, 0.01],\n",
    "#     \"min_samples_leaf\": [0.005, 0.01, 0.02],\n",
    "#     \"min_impurity_decrease\" : [0.001,0.0015,0.002,0.005,0.01],\n",
    "#     \"max_features\": [0.5, 0.75, 1., \"sqrt\"]\n",
    "# }\n",
    "\n",
    "# clf_DT_final = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=5)\n",
    "\n",
    "# clf_DT_final.fit(Xtrainchallenge, Ytrainchallenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clf_DT_final.best_params_)\n",
    "\n",
    "# print(\"Train: \",clf_DT_final.score(Xtrainchallenge, Ytrainchallenge))\n",
    "# y_test_final = clf_DT_final.predict(Xtestchallenge)\n",
    "\n",
    "# np.savetxt('WADE_ArbreDecision_version_2.txt', np.transpose(y_test_final),fmt='% 0d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Precision_test = {}\n",
    "# Precision_train = {}\n",
    "\n",
    "# Precision_final = {}\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=1)\n",
    "\n",
    "# for size in np.linspace(0.05, 0.95, 19):\n",
    "#     print(size,\":\")\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(Xtrainchallenge,Ytrainchallenge,test_size = size)\n",
    "    \n",
    "#     clf_DT.fit(X_train, y_train)\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     Precision_train[size] = round(clf_DT.score(X_train, y_train),2)\n",
    "#     Precision_test[size]  = round(clf_DT.score(X_test, y_test),2)\n",
    "    \n",
    "#     y_pred = clf_DT.predict(Xtestchallenge)\n",
    "    \n",
    "#     Precision_final[size] = f1_score(y_test_final, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(list(Precision_train.keys()), list(Precision_train.values()), 'r-',  label='train')\n",
    "# plt.plot(list(Precision_test.keys()), list(Precision_test.values()), 'b-', label='test')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(list(Precision_final.keys()), list(Precision_final.values()), '-', label='F1 Score')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doonees_Test = pd.DataFrame({\n",
    "#     'Model': ['Decision Tree', 'Random Forest', 'Gradient Boosting','XGBoost'],\n",
    "#     'Accuracy_score': [as_dt, as_rf, as_grad, as_xgrad],\n",
    "#     'Matrice de confusion': [cm_dt, cm_rf, cm_grad, cm_xgrad],\n",
    "#     \"F1 [macro,micro, weighted]\": [f1_dt, f1_rf, f1_grad, f1_xgrad]})\n",
    "    \n",
    "# models_cross.sort_values(by='Accuracy_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_dt = clf_DT.predict(X_test)\n",
    "# confusion_matrix(y_test, y_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construire la courbe ROC\n",
    "# from sklearn import metrics\n",
    "# fpr, tpr, thr = metrics.roc_curve(y_test, y_dt)\n",
    "\n",
    "# # calculer l'aire sous la courbe ROC\n",
    "# auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# # créer une figure\n",
    "# from matplotlib import pyplot as plt\n",
    "# fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "# # afficher la courbe ROC\n",
    "# plt.plot(fpr, tpr, '-', lw=2, label='AUC=%.2f' % auc)\n",
    "\n",
    "# # donner un titre aux axes et au graphique\n",
    "# plt.xlabel('False Positive Rate', fontsize=16)\n",
    "# plt.ylabel('True Positive Rate', fontsize=16)\n",
    "# plt.title('Courbe ROC Décision Tree', fontsize=16)\n",
    "\n",
    "# # afficher la légende\n",
    "# plt.legend(loc=\"lower right\", fontsize=14)\n",
    "\n",
    "# # afficher l'image\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Score_test = {}\n",
    "# Score_train = {}\n",
    "\n",
    "\n",
    "# for variance in range(20):\n",
    "#     print(\"\\nVariance\",variance)\n",
    "    \n",
    "#     Col_train = Xtrainchallenge.std() > variance\n",
    "#     Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "#     Col_test = Xtestchallenge.std() > variance\n",
    "#     Col_test = [i for i in Col_test.index if Col_test[i]==True]\n",
    "\n",
    "#     Col = list(set(Col_train) & set(Col_test))\n",
    "    \n",
    "#     Xtrainchallenge = Xtrainchallenge[Col]\n",
    "#     Xtestchallenge = Xtestchallenge[Col]\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(Xtrainchallenge,Ytrainchallenge,test_size = 0.1)\n",
    "    \n",
    "#     parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.001, 0.005],\n",
    "#     \"min_samples_leaf\": [0.001, 0.005, 0.01, 0.01, 0.05],\n",
    "#     \"max_features\": [1., \"sqrt\"]\n",
    "#     }\n",
    "\n",
    "#     clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=1)\n",
    "\n",
    "#     clf_DT.fit(X_train, y_train)\n",
    "    \n",
    "#     print(\"Train: \",clf_DT.score(X_train, y_train))\n",
    "#     print(\"Test: \",clf_DT.score(X_test, y_test))\n",
    "    \n",
    "#     Score_test[variance] = round(clf_DT.score(X_test, y_test),2)\n",
    "#     Score_train[variance] = round(clf_DT.score(X_train, y_train),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# variance = 1\n",
    "\n",
    "# Col_train = Xtrainchallenge.std() > variance\n",
    "# Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "# Col_test = Xtestchallenge.std() > variance\n",
    "# Col_test = [i for i in Col_test.index if Col_test[i]==True]\n",
    "\n",
    "# Col = list(set(Col_train) & set(Col_test))\n",
    "    \n",
    "# Xtrainchallenge = Xtrainchallenge[Col]\n",
    "# Xtestchallenge = Xtestchallenge[Col]\n",
    "    \n",
    "    \n",
    "# parameters = {\n",
    "#     \"criterion\": [\"gini\", \"entropy\"],\n",
    "#     \"max_depth\":[3, 5, 8, 10],\n",
    "#     \"min_samples_split\": [2, 0.001, 0.005],\n",
    "#     \"min_samples_leaf\": [0.001, 0.005, 0.01, 0.01, 0.05],\n",
    "#     \"max_features\": [1., \"sqrt\"]\n",
    "# }\n",
    "\n",
    "# clf_DT = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "# clf_DT.fit(Xtrainchallenge, Ytrainchallenge)\n",
    "    \n",
    "# print(\"Train: \",clf_DT.score(Xtrainchallenge, Ytrainchallenge))\n",
    "\n",
    "# y_pred = clf_DT .predict(Xtestchallenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf_DT .predict(Xtestchallenge)\n",
    "# np.savetxt('WADE_ArbreDecision.txt', np.transpose(y_pred),fmt='% 0d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 9\n",
    "\n",
    "Col_train = Xtrainchallenge.std() > variance\n",
    "Col_train = [i for i in Col_train.index if Col_train[i]==True]\n",
    "\n",
    "Col_test = Xtestchallenge.std() > variance\n",
    "Col_test = [i for i in Col_test.index if Col_test[i]==True]\n",
    "\n",
    "Col = list(set(Col_train) & set(Col_test))\n",
    "\n",
    "Xtrainchallenge = Xtrainchallenge[Col]\n",
    "Xtestchallenge = Xtestchallenge[Col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#pour les scores\n",
    "from sklearn.metrics import f1_score\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "#ROC Curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #instantiate model and train\n",
    "\n",
    "# n_estimators = [100, 200, 300, 400, 500]\n",
    "# learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "# myXGBoost = XGBClassifier(learning_rate = 0.005, n_estimators=400, max_depth=8)\n",
    "# eval_set = [(X_test, y_test)]\n",
    "# eval_metric = [\"auc\",\"error\",\"logloss\"]\n",
    "# myXGBoost.fit(X_train, y_train, early_stopping_rounds=30, eval_metric=\"error\", eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make predictions for test set\n",
    "# y_pred = myXGBoost.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  99 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 131 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 148 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 167 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 186 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 207 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 228 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 251 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 274 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 299 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 324 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 351 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 378 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 407 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 436 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 467 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 498 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 531 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 599 tasks      | elapsed: 19.3min\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "parameters = {\n",
    "    \"eta\" : [0.1, 0.6],\n",
    "    \"gamma\" : [0.1, 0.66],\n",
    "    \"subsample\": [0.5, 1.0],\n",
    "    \"colsample_bytree\": [0.5, 1.0],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "    \"min_samples_leaf\": [0.01],\n",
    "    \"max_depth\":[8,10],\n",
    "    \"max_features\":[0.5, 1.0],\n",
    "    \"n_estimators\" : [500],\n",
    "    }\n",
    "\n",
    "                \n",
    "clf_XGB = GridSearchCV(XGBClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "eval_set = [(Xtrainchallenge, Ytrainchallenge)]\n",
    "                    \n",
    "clf_XGB.fit(Xtrainchallenge, Ytrainchallenge, early_stopping_rounds=25, eval_metric=\"auc\", eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \",clf_XGB.score(Xtrainchallenge, Ytrainchallenge))\n",
    "print(\"\\n\")\n",
    "print(clf_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'modeles/clf_XGBOOST_2'\n",
    "joblib.dump(clf_XGB, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGB = clf_XGB.predict(Xtestchallenge)\n",
    "np.savetxt('WADE_XGBoost_Version_2.txt', np.transpose(y_pred_XGB),fmt='% 0d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# parameters = {\n",
    "#     \"loss\":[\"deviance\", \"exponential\"],\n",
    "#     \"learning_rate\": [0.001, 0.01],\n",
    "#     \"min_samples_leaf\": [0.00010.01],\n",
    "#      \"min_samples_split\" : [2, 10],\n",
    "#      \"min_impurity_decrease\" : [0.00.005], \n",
    "#     \"max_depth\":[8, 10],\n",
    "#     \"max_features\":[\"sqrt\"],\n",
    "#     \"criterion\": [\"friedman_mse\"],\n",
    "#     \"subsample\":[0.5, 1],\n",
    "#     \"n_estimators\":[500],\n",
    "#     }\n",
    "        \n",
    "# clf_GB = GridSearchCV(GradientBoostingClassifier(), parameters, cv=5, n_jobs=-1,verbose=10)\n",
    "\n",
    "# clf_GB.fit(Xtrainchallenge, Ytrainchallenge)\n",
    "\n",
    "# print(\"Train: \",clf_GB.score(Xtrainchallenge, Ytrainchallenge))\n",
    "# print(\"\\n\")\n",
    "# print(clf_GB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = clf_GB.predict(Xtestchallenge)\n",
    "# np.savetxt('WADE_GradientBoosting_Version_2.txt', np.transpose(y_pred),fmt='% 0d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model to disk\n",
    "# filename = 'modeles/clf_GB_2'\n",
    "# joblib.dump(clf_GB, filename)\n",
    "\n",
    "# # # load the model from disk\n",
    "# # loaded_model = joblib.load('modeles/clf_GB_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Hyperopt est une bibliothèque python pour optimiser les espaces de recherche. Actuellement, il offre deux algorithmes d'optimisation : 1. Recherche aléatoire et 2. Tree of Parzen Estimators (TPE) qui est une approche bayésienne qui utilise P(x|y) au lieu de P(y|x), basée sur l'approximation de deux distributions différentes séparées par un seuil au lieu d'une pour calculer l'amélioration attendue (voir ceci). Auparavant, il s'adaptait aux processus gaussiens et aux arbres de régression, mais aujourd'hui, ils ne sont plus mis en œuvre."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fmin() est la fonction principale d'hyperopt pour l'optimisation. Il accepte quatre arguments de base et sort le jeu de paramètres optimisé :\n",
    "\n",
    "1. Objectif Fonction - fn\n",
    "2. Espace de recherche - espace\n",
    "3. Algorithme de recherche - algo\n",
    "4. (Maximum) nombre d'évaluations - max_evals\n",
    "\n",
    "Nous pouvons également passer un objet Trials à l'argument trials qui garde la trace de tout le processus. Pour fonctionner avec des tracés, la sortie de la fonction objectif doit être un dictionnaire comprenant au moins les clés \"perte\" et \"état\" qui contiennent respectivement le résultat et l'état d'optimisation. Les valeurs intermédiaires pourraient être extraites comme suit :\n",
    "\n",
    "1. trials.trials - une liste de dictionnaires contient toutes les informations pertinentes\n",
    "2. trials.results - une liste de dictionnaires collectant les sorties des fonctions\n",
    "3. trials.losses() - une liste des pertes (flottant pour chaque essai'ok')\n",
    "4. trials.statuses() - une liste de chaînes de statuts\n",
    "5. trials.vals - un dictionnaire des paramètres échantillonnés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score(params):\n",
    "#     num_round = int(params['n_estimators'])\n",
    "#     del params['n_estimators']\n",
    "#     dtrain = xgboost.DMatrix(Xtrainchallenge, label=y_train)\n",
    "#     dvalid = xgboost.DMatrix(Xtestchallenge, label=y_val)\n",
    "#     watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "#     gbm_model = xgboost.train(params, \n",
    "#                               dtrain, \n",
    "#                               num_round,\n",
    "#                               evals=watchlist,\n",
    "#                               verbose_eval=False)\n",
    "#     predictions = gbm_model.predict(dvalid, ntree_limit=gbm_model.best_iteration)\n",
    "#     print(gini_normalized(y_val, np.array(predictions)))\n",
    "#     loss = 1 - gini_normalized(y_val, np.array(predictions))\n",
    "#     return {'loss': loss, 'status': STATUS_OK}\n",
    " \n",
    " \n",
    "# def optimize(evals, cores, trials, optimizer=tpe.suggest, random_state=0):\n",
    "#     space = {\n",
    "#         'n_estimators': hp.quniform('n_estimators', 200, 600, 1),\n",
    "#         'eta': hp.quniform('eta', 0.025, 0.25, 0.025), # A problem with max_depth casted to float instead of int with the hp.quniform method.\n",
    "#         'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "#         'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "#         'subsample': hp.quniform('subsample', 0.7, 1, 0.05),\n",
    "#         'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "#         'colsample_bytree': hp.quniform('colsample_bytree', 0.7, 1, 0.05),\n",
    "#         'alpha' :  hp.quniform('alpha', 0, 10, 1),\n",
    "#         'lambda': hp.quniform('lambda', 1, 2, 0.1),\n",
    "#         'nthread': cores,\n",
    "#         'objective': 'binary:logistic',\n",
    "#         'booster': 'gbtree',\n",
    "#         'seed': random_state\n",
    "#     }\n",
    "#     best = fmin(score, space, algo=tpe.suggest, max_evals=evals, trials = trials)\n",
    "#     return best\n",
    "    \n",
    "\n",
    "# trials = Trials()\n",
    "# cores = 32\n",
    "# n= 1000\n",
    "# start = time.time()\n",
    "# best_param = optimize(evals = n,\n",
    "#                       optimizer=tpe.suggest,\n",
    "#                       cores = cores,\n",
    "#                       trials = trials)\n",
    "# print(\"------------------------------------\")\n",
    "# print(\"The best hyperparameters are: \", \"\\n\")\n",
    "# print(best_param)\n",
    "# end = time.time()\n",
    "# print('Time elapsed to optimize {0} executions: {1}'.format(n,end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Avec un arbre de décision pour une variance de 1, on obtient un score de 73.8%\n",
    "Avec un Gradient Boosting pour une variance de 9, on obtient un score de 77.4%\n",
    "Avec XGBoost_version_1 pour une variance de 9, on obtient un score de 78.4%\n",
    "Avec XGBoost_version_2 pour une variance de 10, on obtient un score de 79.4%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
