install.packages("xgboost")
library("xgboost")
load("C:/Users/plnc629/Downloads/Challenge1.Rdata")
View(Xtestchallenge)
View(Xtrainchallenge)
View(Xtrainchallenge)
setwd("C:/Users/plnc629/Desktop/Master_D_S/Projets/Projets/Series_Chrono/projet")
# quelques outils (tests ADF/KPSS, auto.arima, ...)
library("aTSA")
library("forecast")
# ouverture du fichier
Strates = read.csv("strates.txt")$Strates
n = length(Strates)
# aspect visuel : transformation necessaire
# le log (possible car >0) appaisera les pics, harmonisera la variance, reduira l'echelle des donnees
plot(1:n, Strates, type="l", col="blue", xlab="Temps", ylab="Strates")
LStrates = log(Strates)
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
# pour les tests ADF et KPSS, on se contente ici de Type 1
# (Type 2 et Type 3 regardent la stationnarite des residus apres avoir estime une tendance (respectivement constante et lineaire)
# KPSS (Type 1) : non stationnaire
# ADF (Type 1) : non stationnaire pour des lags raisonnables (on regarde 3 ou 4, par exemple)
kpss.test(LStrates)
adf.test(LStrates)
# pour les tests ADF et KPSS, on se contente ici de Type 1
# (Type 2 et Type 3 regardent la stationnarite des residus apres avoir estime une tendance (respectivement constante et lineaire)
# KPSS (Type 1) : non stationnaire
# ADF (Type 1) : non stationnaire pour des lags raisonnables (on regarde 3 ou 4, par exemple)
kpss.test(LStrates)
adf.test(LStrates)
# une representation graphique superposant la serie avec une moyenne lissee (fenetre de 80)
fen = 80
LStratesLiss = rep(0, n-fen)
for (i in 1:(n-fen)){
LStratesLiss[i] = mean(LStrates[i:(i+fen)])
}
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines((fen/2+1):(n-fen/2), LStratesLiss, col="red", type="p")
# tendance cubique estimee par OLS
Tps = 1:n
Tps2 = (1:n)^2
Tps3 = (1:n)^3
RL = lm(LStrates ~ Tps+Tps2+Tps3)
summary(RL)
# recuperation des coefficients estimes de la tendance et les valeurs reconstruires (Fit = Serie-Res)
Coef = RL$coef
EstTrend = RL$fitted.values
Res = LStrates-EstTrend
MSETendCub = sum(Res^2)
# superposition de la serie avec son estimation
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines(1:n, EstTrend, type="l", col="red")
# residus stationnaires (pour modelisation ARMA) ?
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
kpss.test(Res)
adf.test(Res)
# graphiquement ? (attention a l'effet trompeur du a l'echelle des ordonnees)
fen = 80
ResLissM = rep(0, n-fen)
ResLissV = rep(0, n-fen)
for (i in 1:(n-fen)){
ResLissM[i] = mean(Res[i:(i+fen)])
ResLissV[i] = var(Res[i:(i+fen)])
}
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
lines((fen/2+1):(n-fen/2), ResLissM, col="red", type="p")
lines((fen/2+1):(n-fen/2), ResLissV, col="blue", type="p")
# tendance sinusoidale estimee par OLS (+ grille)
# on fait varier thera pour trouver celui qui minimise le MSE (= somme des carres des residus)
MSEmin = +Inf
for (theta in 300:500){
RL = lm(LStrates ~ cos(2*pi*Tps/theta))
if (sum(RL$residuals^2) < MSEmin){
MSEmin = sum(RL$residuals^2)
thetamin = theta
}
}
# on trouve thetamin = 415 ici
RL = lm(LStrates ~ cos(2*pi*Tps/thetamin))
summary(RL)
# recuperation des coefficients estimes de la tendance et les valeurs reconstruires
Coef = RL$coef
EstTrend = Coef[1] + Coef[2]*cos(2*pi*Tps/thetamin)
Res = LStrates-EstTrend
MSETendSin = MSEmin
# superposition de la serie avec son estimation
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines(1:n, EstTrend, type="l", col="red")
# choix critiquable :
# approxime moins bien la tendance sur les observations que la tendance cubique (comparer les deux MSE)
# bien meilleur en termes d'extrapolation : sous-entend que le phenomene reel sous-jacent se comporte de maniere periodique
print(paste("Tendance cubique : MSE = ", MSETendCub))
print(paste("Tendance sinuoidale : MSE = ", MSETendSin))
# residus stationnaires (pour modelisation ARMA) ?
kpss.test(Res)
adf.test(Res)
# graphiquement ? (attention a l'effet trompeur du a l'echelle des ordonnees)
fen = 80
ResLissM = rep(0, n-fen)
ResLissV = rep(0, n-fen)
for (i in 1:(n-fen)){
ResLissM[i] = mean(Res[i:(i+fen)])
ResLissV[i] = var(Res[i:(i+fen)])
}
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
lines((fen/2+1):(n-fen/2), ResLissM, col="red", type="p")
lines((fen/2+1):(n-fen/2), ResLissV, col="blue", type="p")
# structure de correlation dans les residus : clairement ce n'est pas un bruit blanc
acf(Res, lag=20, main="ACF des residus")
pacf(Res, lag=20, main="PACF des residus")
# on teste les premiers ARMA (de (1,0) a (5,5) par exemple) mais les MA purs sont inutiles vu l'ACF
# il ne faut pas etre trop gourmand dans le nombre de parametres, car n n'est pas infini
# on ne retient pas d'intercept, la serie est centree (mean(Res) est nul)
AICmin = +Inf
for (p in 1:5){
for (q in 0:5){
ARMA = arima(Res, order=c(p,0,q), include.mean=FALSE)
if (ARMA$aic < AICmin){
AICmin = ARMA$aic
pmin = p
qmin = q
}
}
#plot(Res, type="l", col="black")
#FitRes = Res-ARMA$residuals
#lines(FitRes, col="red")
}
# structure de correlation dans les residus : clairement ce n'est pas un bruit blanc
acf(Res, lag=20, main="ACF des residus")
pacf(Res, lag=20, main="PACF des residus")
# on teste les premiers ARMA (de (1,0) a (5,5) par exemple) mais les MA purs sont inutiles vu l'ACF
# il ne faut pas etre trop gourmand dans le nombre de parametres, car n n'est pas infini
# on ne retient pas d'intercept, la serie est centree (mean(Res) est nul)
AICmin = +Inf
for (p in 1:5){
for (q in 0:5){
ARMA = arima(Res, order=c(p,0,q), include.mean=FALSE)
if (ARMA$aic < AICmin){
AICmin = ARMA$aic
pmin = p
qmin = q
}
}
#plot(Res, type="l", col="black")
#FitRes = Res-ARMA$residuals
#lines(FitRes, col="red")
}
# p=4 et q=3 donnent l'AIC minimal
ARMA = arima(Res, order=c(pmin,0,qmin), include.mean=FALSE)
print(ARMA)
# on essaie avec auto.arima
auto.arima(Res, max.p=5, max.q=5, max.d=0, ic="aic")
ARMA12 = arima(Res, order=c(1,0,2), include.mean=FALSE)
ARMA43 = arima(Res, order=c(4,0,3), include.mean=FALSE)
# on retient en premiere analyse ARMA(1,2) et ARMA(4,3)
Res12 = ARMA12$residuals
Res43 = ARMA43$residuals
Fit12 = Res-Res12
Fit43 = Res-Res43
# diagnostics de normalitÃ© des residus
hist(Res12, breaks=sqrt(n), main="Histogramme des residus", freq=FALSE, xlab="Residus", ylab="Densite")
hist(Res43, breaks=sqrt(n), main="Histogramme des residus", freq=FALSE, xlab="Residus", ylab="Densite")
qqnorm(Res12, main="QQ-plot des residus", xlab="Quantiles theoriques", ylab="Quantiles empiriques")
qqnorm(Res43, main="QQ-plot des residus", xlab="Quantiles theoriques", ylab="Quantiles empiriques")
plot(Res12/sd(Res12), type="p", main="Nuage de points des residus", xlab="Temps", ylab="Residus standardises")
abline(h=c(-1.96,1.96), col="red")
plot(Res43/sd(Res43), type="p", main="Nuage de points des residus", xlab="Temps", ylab="Residus standardises")
abline(h=c(-1.96,1.96), col="red")
shapiro.test(Res12)
shapiro.test(Res43)
# diagnostics de blancheur des residus
acf(Res12, main="ACF des residus")
pacf(Res12, main="PACF des residus")
acf(Res43, main="ACF des residus")
pacf(Res43, main="PACF des residus")
plot(Res12[1:(n-1)], Res12[2:n], type="p", main="", xlab="Residus de l'instant t-1", ylab="Residus de l'instant t")
plot(Res43[1:(n-1)], Res43[2:n], type="p", main="", xlab="Residus de l'instant t-1", ylab="Residus de l'instant t")
Box.test(Res12, lag=3)
Box.test(Res43, lag=3)
# on reconstruit la serie avec la tendance sinusoidale et ces deux modeles pour les residus
FitGen12 = EstTrend+Fit12
# diagnostics de blancheur des residus
acf(Res12, main="ACF des residus")
pacf(Res12, main="PACF des residus")
# diagnostics de blancheur des residus
acf(Res12, main="ACF des residus")
pacf(Res12, main="PACF des residus")
acf(Res43, main="ACF des residus")
