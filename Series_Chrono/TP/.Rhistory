plot(Temp, type="l",xlim=c(1,240), xlab="temps(Heure)", ylab="Température")
# trace des donnees
plot(Temp, type="l",xlim=c(1,4800), xlab="temps(Heure)", ylab="Température")
# trace des donnees
plot(Temp, type="l",xlim=c(1,480), xlab="temps(Heure)", ylab="Température")
plot(Temp[1:1500], Conso[1:1500], main="The Sine Function", xlab="temp(Heure)", ylab="Conso")
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)", ylab="Log_Consommation")
# trace des donnees
plot(Conso, type="l", xlim=c(1,480), xlab="temps(Heure)", ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)", ylab="Log_Consommation")
plot(LConso, type="l", xlim=c(1,480), xlab="temps(Heure)", ylab="Log_Consommation")
plot(LConso, type="l", xlim=c(1,4800), xlab="temps(Heure)", ylab="Log_Consommation")
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)", ylab="Log_Consommation")
#On visualizer les donne
library(tseries)
library(forecast)
library(Metrics)
library(ftsa)
library(dLagM)
library(statsr)
install.packages(c("dLagM", "forecast", "ftsa", "Metrics", "statsr", "tseries"))
#On visualizer les donne
library(tseries)
library(forecast)
library(Metrics)
library(ftsa)
library(dLagM)
library(statsr)
acf(Conso)
freq = 12
y = log(Conso)
#On definie la serie chrono
SY = ts(y, frequency=freq)
# decompose la serie entre la tendance, saisonalite et bruit
sx = decompose(SY)
plot(sx)
frequency(sncf$VK)
bruit = sx$random
bru =   bruit[!is.na(bruit)]
bruit = bruit[!is.na(bruit)]
kpss.test(bruit)
adf.test(bruit)
acf(bruit) # on prends q {1, 5, 6, 7, 8, 9, 10, 11}
#pacf s'annule a partir d'un certain rang, on peux prendre  p = 10
#on peut dire que le bruit est un AR(10)
pacf(bruit) #on peut prendre  p {2, 5, 6, 7, 8, 9, 10}
#p= 2 et q= 1 # critere qui minimisent mse
Arm1 = Arima(bruit, order = c(2, 0,2), include.mean = FALSE)
Arm2 = Arima(bruit, order = c(2, 0,4), include.mean = FALSE)
Arm3 = Arima(bruit, order = c(1, 0,3), include.mean = FALSE)
Arm4 = Arima(bruit, order = c(1, 0,2), include.mean = FALSE)
Arm5 = Arima(bruit, order = c(3, 0,2), include.mean = FALSE)#
### Estimation des modele potentiels
#la commande Arm$coef nous donne les coefs de AR et MA
Arm1$coef
Arm2$coef
Arm3$coef
Arm4$coef
Arm5$coef
### Verification des modeles potentiels:
Arm1$coef/sqrt(diag(Arm1$var.coef))
Arm2$coef/sqrt(diag(Arm2$var.coef))
Arm3$coef/sqrt(diag(Arm3$var.coef))
Arm4$coef/sqrt(diag(Arm4$var.coef))
Arm5$coef/sqrt(diag(Arm5$var.coef))
##Blancheur des residues des different model
res1 = (Arm1$residuals)/(sqrt(Arm1$sigma2))
res2 = (Arm2$residuals)/(sqrt(Arm2$sigma2))
res3 = (Arm3$residuals)/(sqrt(Arm3$sigma2))
res4 = (Arm4$residuals)/(sqrt(Arm4$sigma2))
res5 =  (Arm5$residuals)/(sqrt(Arm5$sigma2))
Box.test(res1, lag = 1, type = c("Box-Pierce", "Ljung-Box")) #p-value > 0.05, on constate l'independence
Box.test(res2, lag = 1, type = c("Box-Pierce", "Ljung-Box")) #p-value > 0.05, on constate l'independence
Box.test(res3, lag = 1, type = c("Box-Pierce", "Ljung-Box"))
Box.test(res4, lag = 1, type = c("Box-Pierce", "Ljung-Box"))
Box.test(res5, lag = 1, type = c("Box-Pierce", "Ljung-Box"))
#acf des residues
pacf(res1)
acf(res1)
#Normalit? des residuees: on verifie les 4 tests
hist(res2, breaks=sqrt(length(res2)))  #le hist
plot(res2, type="p")
abline(h=c(-1.96,1.96)) # on verifie que les point sont dans l'inter [-1.96, 1.96]
shapiro.test(res2) #p = 0.8801 nous indique
qqnorm(res2)
plot(res2, type = 'l')
## Choix definitif du modele.
auto.arima(bruit)  #Nous donne la bonne p = 2 et q= 2
#Graphique du bruit et valeurs estimes
var(Arm1$fitted)
plot(Arm1$fitted, type= 'l', col = 'green', main = 'Graphiques des mod?les', ylab = 'log Y')
lines(Arm2$fitted,type = 'l',  col= 'red')
lines(Arm5$fitted, type = 'l' , col= 'blue')
lines(bruit, type= 'l')
w = log(sncf$VK)[7:210]
trend    = as.numeric(sx$trend)[7:210]
w = log(Conso)[7:210]
trend    = as.numeric(sx$trend)[7:210]
seasonal = as.numeric(sx$seasonal)[7:210]
bruit    = as.numeric(sx$random)[7:210]
acf( Arm1$fitted)
#Modelisation de la serie logarithmic
yest = trend + seasonal + Arm1$fitted
y2 = trend + seasonal + Arm2$fitted
y3 = trend +seasonal  + Arm5$fitted
#Modelisation de notre serie
yest = trend + seasonal + Arm1$fitted
plot(exp(yest), type="l", col="red")
lines(exp(y2), type="l", col="blue")
lines(exp(y3), type="l", col="green")
lines((sncf$VK)[7:210], type = 'l')
##############################################
#Calcul de l'erreur
mase(exp(log(sncf$VK)[7:210]), yest)
rmse( (sncf$VK)[7:210], exp(yest))
rmse( (sncf$VK)[7:210], exp(y2))
rmse( (sncf$VK)[7:210], exp(y3))
mape( (sncf$VK)[7:210], exp(yest))
mape( (sncf$VK)[7:210], exp(y2))
mape( (sncf$VK)[7:210], exp(y3))
ytrei = log(sncf$VK)[7:210]
a = 0.05
upper <- trend + seasonal + fitted(Arm1) + qnorm(1-a/2)*sqrt(Arm1$sigma2)
lower <- trend + seasonal + fitted(Arm1) - qnorm(1-a/2)*sqrt(Arm1$sigma2)
plot(exp(ytrei), type="l", ylim=c(min(exp(lower)),max(exp(upper))))
polygon(c(time(exp(ytrei)),rev(time(exp(ytrei)))), c(exp(upper),rev(exp(lower))),
col=rgb(0,0,0.6,0.2), border=FALSE)
lines(exp(yest), type="l", col="red")
#1###Stationarisation de la serie.
Z_t = y
plot(y, type = 'l') #on demontre que la serie n'est pas stationnaire(presence d'une tendance)
#On de V_t la serie VK et on travaille avec Z = log(V_t)
acf(Z_t, lag = 36, ylim=c(-1,1)) #on constate que la serie n'est pas un bruit blanc et il y
y_dif1=diff(y,lag=12)#on effectue une differenciation (I-B)
adf.test(y_dif1)
kpss.test(y_dif1)
#On visualizer les donne
library(tseries)
library(forecast)
library(Metrics)
library(ftsa)
library(dLagM)
library(statsr)
path_Conso = "/users/mmath/wade/Bureau/Projets/Projets/Series_Chrono/projet/Conso.RData"
path_Temp = "/users/mmath/wade/Bureau/Projets/Projets/Series_Chrono/projet/Temp.RData"
load("Conso.RData")
load("Temp.RData")
LConso = log(Conso)
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)", ylab="Log_Consommation")
plot(LConso, type="l", xlab="temps(Heure)",xlim=c(1,480), ylab="Log_Consommation")
plot(LConso, type="l", xlab="temps(Heure)",xlim=c(1,4800), ylab="Log_Consommation")
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", xlim=c(1,480), ylab="Consommation")
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", xlim=c(1,4800), ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)",xlim=c(1,1000), ylab="Log_Consommation")
# trace des donnees
plot(Conso, type="l", xlab="temps(Heure)", xlim=c(1,480), ylab="Consommation")
plot(LConso, type="l", xlab="temps(Heure)",xlim=c(1,960), ylab="Log_Consommation")
setwd("C:/Users/plnc629/Desktop/Master_D_S/Projets/Projets/Series_Chrono/TP")
# ouverture du fichier de donnees (X2815 est le nom donne par defaut a la colonne du tableau)
# il faut au prealable se placer dans le bon repertoire : Session -> Set Working Directory -> ... ou directement setwd(...)
Champ = read.csv("champagne.txt")$X2815
# trace des donnees et des donnees logarithmiques
plot(Champ, type="l", xlab="t", ylab="Ventes")
LChamp = log(Champ)
plot(LChamp, type="l", xlab="t", ylab="Log Ventes")
# autocorrelations empiriques de la series
acf(LChamp, main="ACF empirique")
# notre choix se porte sur une periode de 12
# (une periode de 6 peut etre retenue mais l'experience montre qu'elle ne permet pas de rendre la serie aperiodique)
tau = 12
m = tau/2
nsup = length(LChamp)%%tau
n = length(LChamp)-nsup # on se ramene a un nombre entier de periodes (a eviter lorsque les donnees sont rares)
ResLChamp = LChamp[(n+1):length(LChamp)]
LChamp = LChamp[1:n]
ResChamp = Champ[(n+1):(n+nsup)]
Champ = Champ[1:n]
# filtrage par moyenne mobile arithmetique modifiee d'ordre 6
MMChamp = rep(0, n-2*m)
for (i in 1:(n-2*m)){
MMChamp[i] = (LChamp[i] + LChamp[i+2*m])/(4*m) + sum(LChamp[(i+1):(i+2*m-1)])/(2*m)
}
# representation de la serie filtree : elle est visuellement aperiodique
plot(MMChamp, type="l", xlab="t", ylab="Log Ventes apres moyenne mobile")
# espace des temps observables (prive des m premieres et dernieres valeurs)
Tps = 1:(n-2*m)
Tps2 = Tps^2
# M1
RegLinM1 = lm(MMChamp ~ 1+Tps+Tps2)
summary(RegLinM1)
b0M1 = RegLinM1$coefficients[1]
b1M1 = RegLinM1$coefficients[2]
b2M1 = RegLinM1$coefficients[3]
lines(b0M1 + b1M1*Tps + b2M1*Tps2, type="l", col="red")
# M2
RegLinM2 = lm(MMChamp ~ 1+Tps)
summary(RegLinM2)
b0M2 = RegLinM2$coefficients[1]
b1M2 = RegLinM2$coefficients[2]
lines(b0M2 + b1M2*Tps, type="l", col="blue")
# package pour les GLS
library("nlme")
# M3
RegLinGenM3 = gls(MMChamp ~ 1+Tps+Tps2, correlation = corARMA(p=0, q=1))
b0M3 = RegLinGenM3$coefficients[1]
b1M3 = RegLinGenM3$coefficients[2]
b2M3 = RegLinGenM3$coefficients[3]
lines(b0M3 + b1M3*Tps + b2M3*Tps2, type="l", col="magenta")
# M4
RegLinGenM4 = gls(MMChamp ~ 1+Tps+Tps2, correlation = corARMA(p=1, q=0))
b0M4 = RegLinGenM4$coefficients[1]
b1M4 = RegLinGenM4$coefficients[2]
b2M4 = RegLinGenM4$coefficients[3]
lines(b0M4 + b1M4*Tps + b2M4*Tps2, type="l", col="forestgreen")
# pour chacun des modeles, on recupere l'estimation de la tendance sur tout l'espace des temps
EstM1 = b0M1 + b1M1*(1:n) + b2M1*(1:n)^2
EstM2 = b0M2 + b1M2*(1:n)
EstM3 = b0M3 + b1M3*(1:n) + b2M3*(1:n)^2
EstM4 = b0M4 + b1M4*(1:n) + b2M4*(1:n)^2
# superposition du signal et de la tendance estimee
plot(LChamp, type="l", xlab="t", ylab="Log Ventes")
lines(EstM1, type="l", col="red")
lines(EstM2, type="l", col="blue")
lines(EstM3, type="l", col="magenta")
lines(EstM4, type="l", col="forestgreen")
# recuperation du signal prive de sa tendance, pour estimer la saisonnalite
SaisM1 = LChamp - EstM1
SaisM2 = LChamp - EstM2
SaisM3 = LChamp - EstM3
SaisM4 = LChamp - EstM4
# representation des signaux prives de leur tendance
plot(SaisM1, type="l", xlab="t", ylab="Log Ventes sans tendance", col="red")
lines(SaisM2, type="l", col="blue")
lines(SaisM3, type="l", col="magenta")
lines(SaisM4, type="l", col="forestgreen")
# le motif periodique est un vecteur de taille 12
MotifM1 = rep(0, tau)
MotifM2 = rep(0, tau)
MotifM3 = rep(0, tau)
MotifM4 = rep(0, tau)
# on moyennise toutes les periodes extraites des signaux
for (k in 1:tau){
Extr = SaisM1[seq(k, n, by=tau)]
MotifM1[k] = mean(Extr)
Extr = SaisM2[seq(k, n, by=tau)]
MotifM2[k] = mean(Extr)
Extr = SaisM3[seq(k, n, by=tau)]
MotifM3[k] = mean(Extr)
Extr = SaisM4[seq(k, n, by=tau)]
MotifM4[k] = mean(Extr)
}
# on recentre le motif pour qu'il satisfasse la contrainte d'identifiabilite du modele
MotifM1 = MotifM1 - mean(MotifM1)
MotifM2 = MotifM2 - mean(MotifM2)
MotifM3 = MotifM3 - mean(MotifM3)
MotifM4 = MotifM4 - mean(MotifM4)
# representation des motifs periodiques estimes
plot(MotifM1, type="l", xlab="t", ylab="Motif periodique", col="red")
lines(MotifM2, type="l", col="blue")
lines(MotifM3, type="l", col="magenta")
lines(MotifM4, type="l", col="forestgreen")
# estimation de la saisonnalite par duplication du motif
EstSaisM1 = rep(MotifM1, n/tau)
EstSaisM2 = rep(MotifM2, n/tau)
EstSaisM3 = rep(MotifM3, n/tau)
EstSaisM4 = rep(MotifM4, n/tau)
# superposition du signal et de la somme de la tendance et de la saisonnalite estimees
plot(LChamp, type="l", xlab="t", ylab="Log Ventes")
lines(EstM1+EstSaisM1, type="l", col="red")
lines(EstM2+EstSaisM2, type="l", col="blue")
lines(EstM3+EstSaisM3, type="l", col="magenta")
lines(EstM4+EstSaisM4, type="l", col="forestgreen")
# recuperation de la fluctuation residuelle
ResM1 = LChamp - EstM1 - EstSaisM1
ResM2 = LChamp - EstM2 - EstSaisM2
ResM3 = LChamp - EstM3 - EstSaisM3
ResM4 = LChamp - EstM4 - EstSaisM4
# calcul de l'erreur MSE commise lorsqu'on estime le signal par la somme de sa tendance et de sa saisonnalite
MSEM1 = mean((ResM1)^2)
MSEM2 = mean((ResM2)^2)
MSEM3 = mean((ResM3)^2)
MSEM4 = mean((ResM4)^2)
# autocorrelations empiriques des residus pour detecter des correlations et/ou une saisonnalite non eliminee
acf(ResM1, main="ACF empirique")
acf(ResM2, main="ACF empirique") # presence de correlations ici, raison supplementaire pour rejeter le modele M2 par rapport aux autres
acf(ResM3, main="ACF empirique")
acf(ResM4, main="ACF empirique")
# on souhaite predire l'annee suivante
NTps = (n+1):(n+tau)
PredM1 = b0M1 + b1M1*NTps + b2M1*NTps^2 + MotifM1
PredM2 = b0M2 + b1M2*NTps + MotifM2
PredM3 = b0M3 + b1M3*NTps + b2M3*NTps^2 + MotifM3
PredM4 = b0M4 + b1M4*NTps + b2M4*NTps^2 + MotifM4
# representation du signal et de nos previsions par les 4 modeles
plot(1:n, LChamp, type="l", xlab="t", ylab="Log Ventes", xlim=c(1, n+tau))
lines((n+1):(n+nsup), ResLChamp, type="l", col="black", lty=2)
lines(NTps, PredM1, type="l", col="red")
lines(NTps, PredM2, type="l", col="blue")
lines(NTps, PredM3, type="l", col="magenta")
lines(NTps, PredM4, type="l", col="forestgreen")
# representation du signal initial et de nos previsions par les 4 modeles
plot(1:n, Champ, type="l", xlab="t", ylab="Ventes", xlim=c(1, n+tau))
lines((n+1):(n+nsup), ResChamp, type="l", col="black", lty=2)
lines(NTps, exp(PredM1), type="l", col="red")
lines(NTps, exp(PredM2), type="l", col="blue")
lines(NTps, exp(PredM3), type="l", col="magenta")
lines(NTps, exp(PredM4), type="l", col="forestgreen")
# on illustre pour conclure l'application de la procedure "decompose" qui realise la modelisation additive
LChampTS = ts(LChamp, frequency=tau)
Decomp = decompose(LChampTS)
plot(Decomp)
# comparaison entre le motif periodique issu de "decompose" et celui de notre meilleur modele
plot(Decomp$figure, xlab="t", ylab="Motif periodique", type="l")
# on illustre pour conclure l'application de la procedure "decompose" qui realise la modelisation additive
LChampTS = ts(LChamp, frequency=tau)
Decomp = decompose(LChampTS)
plot(Decomp)
# comparaison entre le motif periodique issu de "decompose" et celui de notre meilleur modele
plot(Decomp$figure, xlab="t", ylab="Motif periodique", type="l")
lines(MotifM4, col="forestgreen")
# plus rapide ?
# plus rapide ?
# par contre, R n'estime pas la tendance : donc, pas de prediction !
# plus rapide ?
# par contre, R n'estime pas la tendance : donc, pas de prediction !
# plus rapide ?
# par contre, R n'estime pas la tendance : donc, pas de prediction !
# plus rapide ?
# par contre, R n'estime pas la tendance : donc, pas de prediction !
install.packages("aTSA")
# quelques outils (tests ADF/KPSS, auto.arima, ...)
library("aTSA")
library("forecast")
# ouverture du fichier
Strates = read.csv("strates.txt")$Strates
n = length(Strates)
# aspect visuel : transformation necessaire
# le log (possible car >0) appaisera les pics, harmonisera la variance, reduira l'echelle des donnees
plot(1:n, Strates, type="l", col="blue", xlab="Temps", ylab="Strates")
LStrates = log(Strates)
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
# pour les tests ADF et KPSS, on se contente ici de Type 1
# (Type 2 et Type 3 regardent la stationnarite des residus apres avoir estime une tendance (respectivement constante et lineaire)
# KPSS (Type 1) : non stationnaire
# ADF (Type 1) : non stationnaire pour des lags raisonnables (on regarde 3 ou 4, par exemple)
kpss.test(LStrates)
adf.test(LStrates)
# une representation graphique superposant la serie avec une moyenne lissee (fenetre de 80)
fen = 80
LStratesLiss = rep(0, n-fen)
for (i in 1:(n-fen)){
LStratesLiss[i] = mean(LStrates[i:(i+fen)])
}
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines((fen/2+1):(n-fen/2), LStratesLiss, col="red", type="p")
# tendance cubique estimee par OLS
Tps = 1:n
Tps2 = (1:n)^2
Tps3 = (1:n)^3
RL = lm(LStrates ~ Tps+Tps2+Tps3)
summary(RL)
# recuperation des coefficients estimes de la tendance et les valeurs reconstruires (Fit = Serie-Res)
Coef = RL$coef
EstTrend = RL$fitted.values
Res = LStrates-EstTrend
MSETendCub = sum(Res^2)
# superposition de la serie avec son estimation
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines(1:n, EstTrend, type="l", col="red")
# residus stationnaires (pour modelisation ARMA) ?
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
kpss.test(Res)
adf.test(Res)
# graphiquement ? (attention a l'effet trompeur du a l'echelle des ordonnees)
fen = 80
ResLissM = rep(0, n-fen)
ResLissV = rep(0, n-fen)
for (i in 1:(n-fen)){
ResLissM[i] = mean(Res[i:(i+fen)])
ResLissV[i] = var(Res[i:(i+fen)])
}
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
lines((fen/2+1):(n-fen/2), ResLissM, col="red", type="p")
lines((fen/2+1):(n-fen/2), ResLissV, col="blue", type="p")
# tendance sinusoidale estimee par OLS (+ grille)
# on fait varier thera pour trouver celui qui minimise le MSE (= somme des carres des residus)
MSEmin = +Inf
for (theta in 300:500){
RL = lm(LStrates ~ cos(2*pi*Tps/theta))
if (sum(RL$residuals^2) < MSEmin){
MSEmin = sum(RL$residuals^2)
thetamin = theta
}
}
# on trouve thetamin = 415 ici
RL = lm(LStrates ~ cos(2*pi*Tps/thetamin))
summary(RL)
# recuperation des coefficients estimes de la tendance et les valeurs reconstruires
Coef = RL$coef
EstTrend = Coef[1] + Coef[2]*cos(2*pi*Tps/thetamin)
Res = LStrates-EstTrend
MSETendSin = MSEmin
# superposition de la serie avec son estimation
plot(1:n, LStrates, type="l", col="blue", xlab="Temps", ylab="Strates logarithmiques")
lines(1:n, EstTrend, type="l", col="red")
# choix critiquable :
# approxime moins bien la tendance sur les observations que la tendance cubique (comparer les deux MSE)
# bien meilleur en termes d'extrapolation : sous-entend que le phenomene reel sous-jacent se comporte de maniere periodique
print(paste("Tendance cubique : MSE = ", MSETendCub))
print(paste("Tendance sinuoidale : MSE = ", MSETendSin))
# residus stationnaires (pour modelisation ARMA) ?
kpss.test(Res)
adf.test(Res)
# graphiquement ? (attention a l'effet trompeur du a l'echelle des ordonnees)
fen = 80
ResLissM = rep(0, n-fen)
ResLissV = rep(0, n-fen)
for (i in 1:(n-fen)){
ResLissM[i] = mean(Res[i:(i+fen)])
ResLissV[i] = var(Res[i:(i+fen)])
}
plot(Res, type="l", col="red", xlab="Temps", ylab="Residus de la modelisation")
lines((fen/2+1):(n-fen/2), ResLissM, col="red", type="p")
lines((fen/2+1):(n-fen/2), ResLissV, col="blue", type="p")
# structure de correlation dans les residus : clairement ce n'est pas un bruit blanc
acf(Res, lag=20, main="ACF des residus")
pacf(Res, lag=20, main="PACF des residus")
# on teste les premiers ARMA (de (1,0) a (5,5) par exemple) mais les MA purs sont inutiles vu l'ACF
# il ne faut pas etre trop gourmand dans le nombre de parametres, car n n'est pas infini
# on ne retient pas d'intercept, la serie est centree (mean(Res) est nul)
AICmin = +Inf
for (p in 1:5){
for (q in 0:5){
ARMA = arima(Res, order=c(p,0,q), include.mean=FALSE)
if (ARMA$aic < AICmin){
AICmin = ARMA$aic
pmin = p
qmin = q
}
}
#plot(Res, type="l", col="black")
#FitRes = Res-ARMA$residuals
#lines(FitRes, col="red")
}
# p=4 et q=3 donnent l'AIC minimal
ARMA = arima(Res, order=c(pmin,0,qmin), include.mean=FALSE)
print(ARMA)
# on essaie avec auto.arima
auto.arima(Res, max.p=5, max.q=5, max.d=0, ic="aic")
ARMA12 = arima(Res, order=c(1,0,2), include.mean=FALSE)
ARMA43 = arima(Res, order=c(4,0,3), include.mean=FALSE)
# on retient en premiere analyse ARMA(1,2) et ARMA(4,3)
Res12 = ARMA12$residuals
Res43 = ARMA43$residuals
Fit12 = Res-Res12
Fit43 = Res-Res43
# diagnostics de normalitÃ© des residus
hist(Res12, breaks=sqrt(n), main="Histogramme des residus", freq=FALSE, xlab="Residus", ylab="Densite")
hist(Res43, breaks=sqrt(n), main="Histogramme des residus", freq=FALSE, xlab="Residus", ylab="Densite")
qqnorm(Res12, main="QQ-plot des residus", xlab="Quantiles theoriques", ylab="Quantiles empiriques")
qqnorm(Res43, main="QQ-plot des residus", xlab="Quantiles theoriques", ylab="Quantiles empiriques")
plot(Res12/sd(Res12), type="p", main="Nuage de points des residus", xlab="Temps", ylab="Residus standardises")
abline(h=c(-1.96,1.96), col="red")
plot(Res43/sd(Res43), type="p", main="Nuage de points des residus", xlab="Temps", ylab="Residus standardises")
abline(h=c(-1.96,1.96), col="red")
shapiro.test(Res12)
shapiro.test(Res43)
# diagnostics de blancheur des residus
acf(Res12, main="ACF des residus")
pacf(Res12, main="PACF des residus")
acf(Res43, main="ACF des residus")
pacf(Res43, main="PACF des residus")
plot(Res12[1:(n-1)], Res12[2:n], type="p", main="", xlab="Residus de l'instant t-1", ylab="Residus de l'instant t")
plot(Res43[1:(n-1)], Res43[2:n], type="p", main="", xlab="Residus de l'instant t-1", ylab="Residus de l'instant t")
Box.test(Res12, lag=3)
Box.test(Res43, lag=3)
# on reconstruit la serie avec la tendance sinusoidale et ces deux modeles pour les residus
FitGen12 = EstTrend+Fit12
FitGen43 = EstTrend+Fit43
plot(1:n, Strates, type="l", col="blue", xlab="Temps", ylab="Strates")
lines(1:n, exp(FitGen12), type="l", col="red")
lines(1:n, exp(FitGen43), type="l", col="magenta")
legend("topright", legend = c("Sin+ARMA(1,2)", "Sin+ARMA(4,3)"), col=c("red", "magenta"), lty=c(1,1))
MSE12 = sum((Strates - exp(FitGen12))^2)
MSE43 = sum((Strates - exp(FitGen43))^2)
print(paste("MSE de la reconstruction avec le modele ARMA(1,2) sur les residus = ", MSE12))
print(paste("MSE de la reconstruction avec le modele ARMA(4,3) sur les residus = ", MSE43))
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
# au sens de ce critere, on aurait tendance a preferer in fine le modele tendance sinusoidale+ARMA(4,3) sur le residu
# on pourrait evidemment continuer a creuser avec d'autres modelisations sur les residus...
